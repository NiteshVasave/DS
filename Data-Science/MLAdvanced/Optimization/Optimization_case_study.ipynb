{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"360\" /></center>\n",
    "\n",
    "<h1><center>OPTIMIZATION</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#section1)<br>\n",
    "2. [Batch Gradient Descent (BGD/GD)](#section2)<br>\n",
    "    - 2.1 [Disadvantages of Batch Gradient Descent](#section201)<br>\n",
    "3. [Stochastic Gradient Descent (SGD)](#section3)<br>\n",
    "    - 3.1 [Advantages of Stochastic Gradient Descent](#section301)<br>\n",
    "    - 3.2 [Disadvantages of Stochastic Gradient Descent](#section302)<br>\n",
    "4. [Learning Rate](#section4)<br>\n",
    "5. [Task at Hand](#section5)<br>\n",
    "6. [Dataset Description](#section6)<br>\n",
    "7. [Logistic Regression](#section7)<br>\n",
    "    - 7.1 [LogisticRegression Model Evaluation](#section701)<br>\n",
    "8. [SGD Classifier](#section8)<br>\n",
    "    - 8.1 [SGD Classifier Model Evaluation](#section801)<br>\n",
    "    - 8.2 [Evaluating performance of SGD Classifier for no.of epochs ranging from 1 to 20](#section802)<br>\n",
    "    - 8.3 [Evaluating performance of SGD Classifier for different learning_rates](#section803)<br>\n",
    "    - 8.4 [GridSearchCV on for SGD Classifier](#section804)<br>\n",
    "9. [Conclusion](#section9)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1. Introduction\n",
    "__Optimization__ is the most __essential ingredient__ in the recipe of machine learning algorithms. It starts with defining some kind of loss __function/cost__ function and ends with minimizing the it using one or the other optimization routine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## 2. Batch Gradient Descent (BGD/GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In **Batch Gradient Descent optimazation**, **parameters** are **updated** after **calculating the cost function** on the **entire dataset**. That means, to take **one step** in the gradient descent optimization **towards minimum**, the **entire dataset** is taken into account to **calculate the cost function**.\n",
    "<br>\n",
    "<br>\n",
    " - To take **another step towards the minimum, gradient descent optimization algorithm** should go through the **entire dataset again** to calculate the cost function.\n",
    "<br>\n",
    "<br>\n",
    " - This approach works **fine** for **small datasets.**\n",
    "<br>\n",
    "<br>\n",
    " - But, what **if** our **dataset** is **very large?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section101></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section201\"></a>\n",
    "### 2.1 Disadvantages of Batch Gradient Descent\n",
    "\n",
    " - Say you want to build a **ML model on India Census data**. This dataset will have **133 92 00 000 records**. Thats 133.92 crores records.\n",
    "<br>\n",
    "<br>\n",
    " - To move one step closer to the minimum of cost function, Batch Gradient Descent optimization algorithm calculates cost function on the entire dataset.\n",
    "<br>\n",
    "<br>\n",
    " - This characteristic of Batch Gradient Descent makes it **computationaly very expensive** which leads to consuption of **more time to converge to minimum.**\n",
    "<br>\n",
    "<br>\n",
    " - What if the optimization algorithm doesn't have to go through all data to take a step towards minimum of cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## 3. Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In this variant of Gradient Descent, The optimization algorithm looks at **one record(random) at a time** to take **a step** in the gradinet descent.\n",
    "<br>\n",
    "<br>\n",
    " - So the algorithm has **already(right from the first instance itself) started** it's journey towards minimum of cost function **unlike Batch Gradient Descent** where it has to go through **entire dataset** to take **one single step.**\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section301\"></a>\n",
    "### 3.1 Advantages of Stochastic Gradient Descent\n",
    " - Takes __less time__ to converge to the __minimum__ of COST FUNCITON\n",
    " \n",
    "<h4><center>Batch Gradient Descent</center></h4>\n",
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/15.gif\"/>\n",
    "<h4><center>Stochastic Gradient Descent</center></h4>\n",
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/14.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Stochastic Gradient Descent doesn't** suffer from the problem of **getting trapped in local minima.**\n",
    " <br>\n",
    " <br>\n",
    "<h4><center>Our cost function curve can be a simple convex curve.</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/1.png\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><center>Or a complex curve which has local minims and a global minimum</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/2.png\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - When **cost function** has **multiple local minima and a global minimum**, then **Batch Gradient Descent** has a chance to get **trapped in the local minima**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/3.gif\" width=\"500\" height=\"400\" />\n",
    " - Stochastic Gradient Descent eliminates this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - One another reason you might want to use Stochastic Gradient Descent, **Batch Gradient Descent, won’t work** if you can’t hold the **entire dataset** in **RAM** but **SGD will still work (Mini Batch Gradient Descent)**. We will look at this in the end of this case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section201></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section302\"></a>\n",
    "### 3.2 Disadvantages of Stochastic Gradient Descent\n",
    " - **SGD** often **converges much faster** compared to **GD** **but** the **error function** is **not** as **well minimized** **as in the case of GD**. Often **in most cases**, **the close approximation** that **you get in SGD** for the **parameter** values **are enough** because **they reach the optimal values and keep oscillating there.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Process:\n",
    "- The training data is divided into batches\n",
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/7.png\" width=\"500\" height=\"400\" />\n",
    "   - First batch is taken.\n",
    "   - Weights are initialized with random values.\n",
    "   - Cost Function is calculated considering 1st batch of the data.\n",
    "   - Weights are updated.\n",
    "   - Then second batch of data is taken.\n",
    "   - Cost Function is calculated considering 2nd batch of data with updated weights.\n",
    "   - Weights are updated again.\n",
    "   - Then third batch of data is taken.\n",
    "   - The process continous for specified no.of epochs(no.of times the model sees the entire dataset).\n",
    "    \n",
    "**Batch size can affect the time taken to converge or even final accuracy(or Cost Function).\n",
    "Right Batch size can be arrived using GridSearchCV.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><center>Batch Gradient Descent vs Mini Batch Gradient Descent</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/17.gif\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section301></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "## 4. Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It is used to **control step size** while **gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of gradient descent for different learning rates on a toy example.\n",
    "<br>\n",
    "<br>\n",
    "The below learnin_rates are used for animation purpose only. The optimum learning_rate will vary from dataset to dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - learning_rate = **0.05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/6.gif\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - learning_rate = **0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If learning_rate is **too big**, you’ll move more **quickly**, but you have a **high risk** that the algorithm **will never converge**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/4.gif\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm has **become unstable** and move so fast that it always goes so far.\n",
    "Eventually… it’ll **never get to the minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - If learning_rate is **too small**, you’ll move slowly.. so slowly you might just lose patience and **never reach the minimum**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/insaid2018/optimization-files/master/5.gif\" width=\"500\" height=\"400\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh..\n",
    "\n",
    "I had to speed up the animation, otherwise you’d be bored to death.\n",
    "\n",
    "Instead of getting to the **minimum in 15 iterations(as in first case)**, you get there in **75 iterations! That’s 5 times longer!**\n",
    "\n",
    "In **deep learning**, that makes a **huge difference**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also see the affect of different learnin_rates on performance of SGDClassifier in the end of this case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "## 5. Task at Hand\n",
    " - First we will build a **LogisticRegression model** and check the **time taken to train the model**. We will then build a **SGDClassifier model** and **compare time taken to train this model with LogisticRegression model**. We will also compare different accuracy metrics of both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "## 6. Dataset Description\n",
    " - The dataset is related to a __bank__.\n",
    " - The dataset is about whether a customer has __cleared loan__ or __not__.\n",
    " - Target variable is __Loan Status__ which is a categorical variable.\n",
    " - The target variable has two levels\n",
    "   - __Fully Paid__ means the customer has cleared the loan\n",
    "   - __Charged Off__ means the customer has not cleared the loan\n",
    " - Our objective is to predicted if a customer will clear the loan or not based on the inputs like \n",
    " \n",
    "     - __Current Loan Amount__ :  The listed amount of the loan applied for by the borrower.\n",
    "     - __Term__ :  Time period for which loan is applied.\n",
    "     - __Credit Score__ : Credit score of teh borrower.\n",
    "     - __Annual Income__ : Annual Income of the applicant.\n",
    "     - __Years in current job__\n",
    "     - __Home Ownership__ : The home ownership status provided by the borrower during registration. \n",
    "     - __Purpose__ : Purpose of the Loan\n",
    "     - __Monthly Debt__: Monthly dept of the borrower\n",
    "     - __Maximum Open Credit__ : Maximum number of open credit does the borrower have.\n",
    "     - __Tax Lines__ : Number of Tax lines borrower have.\n",
    "     \n",
    "     etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing pandas package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: For the given data set it's important that here that we are directly using preprocessed data. Because over here our main objective it to have better understanding of Optimization algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('https://github.com/insaid2018/Term-4/raw/master/Data/Assignment/bank_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Tax Liens</th>\n",
       "      <th>...</th>\n",
       "      <th>Purpose_Medical Bills</th>\n",
       "      <th>Purpose_Other</th>\n",
       "      <th>Purpose_major_purchase</th>\n",
       "      <th>Purpose_moving</th>\n",
       "      <th>Purpose_other</th>\n",
       "      <th>Purpose_renewable_energy</th>\n",
       "      <th>Purpose_small_business</th>\n",
       "      <th>Purpose_vacation</th>\n",
       "      <th>Purpose_wedding</th>\n",
       "      <th>Loan Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445412.0</td>\n",
       "      <td>709.000000</td>\n",
       "      <td>1.167493e+06</td>\n",
       "      <td>5214.74</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>228190.0</td>\n",
       "      <td>416746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262328.0</td>\n",
       "      <td>1076.275101</td>\n",
       "      <td>1.378339e+06</td>\n",
       "      <td>33295.98</td>\n",
       "      <td>21.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229976.0</td>\n",
       "      <td>850784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999999.0</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>2.231892e+06</td>\n",
       "      <td>29200.53</td>\n",
       "      <td>14.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>297996.0</td>\n",
       "      <td>750090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347666.0</td>\n",
       "      <td>721.000000</td>\n",
       "      <td>8.069490e+05</td>\n",
       "      <td>8741.90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256329.0</td>\n",
       "      <td>386958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176220.0</td>\n",
       "      <td>1076.275101</td>\n",
       "      <td>1.378339e+06</td>\n",
       "      <td>20639.70</td>\n",
       "      <td>6.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253460.0</td>\n",
       "      <td>427174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Loan Amount  Credit Score  Annual Income  Monthly Debt  \\\n",
       "0             445412.0    709.000000   1.167493e+06       5214.74   \n",
       "1             262328.0   1076.275101   1.378339e+06      33295.98   \n",
       "2           99999999.0    741.000000   2.231892e+06      29200.53   \n",
       "3             347666.0    721.000000   8.069490e+05       8741.90   \n",
       "4             176220.0   1076.275101   1.378339e+06      20639.70   \n",
       "\n",
       "   Years of Credit History  Number of Open Accounts  \\\n",
       "0                     17.2                      6.0   \n",
       "1                     21.1                     35.0   \n",
       "2                     14.9                     18.0   \n",
       "3                     12.0                      9.0   \n",
       "4                      6.1                     15.0   \n",
       "\n",
       "   Number of Credit Problems  Current Credit Balance  Maximum Open Credit  \\\n",
       "0                        1.0                228190.0             416746.0   \n",
       "1                        0.0                229976.0             850784.0   \n",
       "2                        1.0                297996.0             750090.0   \n",
       "3                        0.0                256329.0             386958.0   \n",
       "4                        0.0                253460.0             427174.0   \n",
       "\n",
       "   Tax Liens  ...  Purpose_Medical Bills  Purpose_Other  \\\n",
       "0        0.0  ...                      0              0   \n",
       "1        0.0  ...                      0              0   \n",
       "2        0.0  ...                      0              0   \n",
       "3        0.0  ...                      0              0   \n",
       "4        0.0  ...                      0              0   \n",
       "\n",
       "   Purpose_major_purchase  Purpose_moving  Purpose_other  \\\n",
       "0                       0               0              0   \n",
       "1                       0               0              0   \n",
       "2                       0               0              0   \n",
       "3                       0               0              0   \n",
       "4                       0               0              0   \n",
       "\n",
       "   Purpose_renewable_energy  Purpose_small_business  Purpose_vacation  \\\n",
       "0                         0                       0                 0   \n",
       "1                         0                       0                 0   \n",
       "2                         0                       0                 0   \n",
       "3                         0                       0                 0   \n",
       "4                         0                       0                 0   \n",
       "\n",
       "   Purpose_wedding  Loan Status  \n",
       "0                0   Fully Paid  \n",
       "1                0   Fully Paid  \n",
       "2                0   Fully Paid  \n",
       "3                0   Fully Paid  \n",
       "4                0   Fully Paid  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section8></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79835, 41)\n",
      "(19959, 41)\n",
      "(79835, 1)\n",
      "(19959, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract independent variables\n",
    "features = bank_data.drop('Loan Status',axis = 1)\n",
    "# Extract target variable\n",
    "targets = pd.DataFrame(bank_data['Loan Status'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into 80% training and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of train and test data(Independent variables/Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "# While scaling the test data, mean and standard deviation of train data\n",
    "# should be considered.\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dependent variable into dummy column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Encoding the Dependent Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y_train = LabelEncoder()\n",
    "y_train = labelencoder_y_train.fit_transform(y_train)\n",
    "labelencoder_y_test = LabelEncoder()\n",
    "y_test = labelencoder_y_test.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following encoding is given to 'Loan Status column':\n",
    "**Fully Paid = 1\n",
    "Charged Off = 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check frequency in 'Loan Status' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 18030, 1: 61805})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "## 7. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments for LogisticRegression model:**\n",
    "<br>\n",
    "<br>\n",
    "1.max_iter(epochs) = 100 by default\n",
    "<br>\n",
    "2.Batch Gradient Descent Optimization - by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.71 s\n"
     ]
    }
   ],
   "source": [
    "%time log_model = log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a note of time in milli-seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_lm = log_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section901></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section701\"></a>\n",
    "### 7.1 LogisticRegression Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of our model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819277259347404"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_pred_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score above 80% can be considered a descent model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3656 14374]\n",
      " [   54 61751]]\n"
     ]
    }
   ],
   "source": [
    "cm_train_lm = confusion_matrix(y_train,y_train_pred_lm)\n",
    "print(cm_train_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Precision is more important in this case.**\n",
    " - False Positives should be as less as possible.\n",
    " - **False Positives in this case means the model is predicting that person has cleared the loan but the actually didn't clear the loan.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999126284281207"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train_lm[1,1]/(cm_train_lm[1,1]+cm_train_lm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111789819376026"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train_lm[1,1]/(cm_train_lm[1,1]+cm_train_lm[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_lm = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8186782904955158"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  960  3597]\n",
      " [   22 15380]]\n"
     ]
    }
   ],
   "source": [
    "cm_test_lm = confusion_matrix(y_test,y_test_pred_lm)\n",
    "print(cm_test_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998571614076094"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test_lm[1,1]/(cm_test_lm[1,1]+cm_test_lm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104547610265058"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test_lm[1,1]/(cm_test_lm[1,1]+cm_test_lm[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section10></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section8\"></a>\n",
    "## 8. SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments for SGD Classifier model:**\n",
    "<br>\n",
    "1. max_iter(epochs) = 5 by default\n",
    "<br>\n",
    "2. Stochastic Gradient Descent - by default\n",
    "<br>\n",
    "3. loss = 'log' since we are comparing with LogisticRegression model which uses log loss as cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import SGDClassifier from sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(loss = 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. Take a note of the time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%time sgd_model = sgd_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1001></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section801'></a>\n",
    "### 8.1 SGDClassifier Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_sgd = sgd_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091939625477548"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_pred_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4209 13821]\n",
      " [ 1412 60393]]\n"
     ]
    }
   ],
   "source": [
    "cm_train_sgd = confusion_matrix(y_train,y_train_pred_sgd)\n",
    "print(cm_train_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771539519456355"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train_sgd[1,1]/(cm_train_sgd[1,1]+cm_train_sgd[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137682916969844"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train_sgd[1,1]/(cm_train_sgd[1,1]+cm_train_sgd[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_sgd = sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of SGDClassifier model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076556941730547"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1100  3457]\n",
      " [  382 15020]]\n"
     ]
    }
   ],
   "source": [
    "cm_test_sgd = confusion_matrix(y_test,y_test_pred_sgd)\n",
    "print(cm_test_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9751980262303597"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test_sgd[1,1]/(cm_test_sgd[1,1]+cm_test_sgd[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129025274665801"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test_sgd[1,1]/(cm_test_sgd[1,1]+cm_test_sgd[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1002></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section802\"></a>\n",
    "### 8.2 Evaluating performance of SGD Classifier for no.of epochs ranging from 1 to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_accuracy_list_epochs = []\n",
    "train_accuracy_list_epochs = []\n",
    "\n",
    "for  i in range(1,21):\n",
    "    \n",
    "    sgd = SGDClassifier(max_iter=i,loss = 'log')\n",
    "    sgd_model = sgd.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_preds = sgd_model.predict(X_train)\n",
    "    y_test_preds = sgd_model.predict(X_test)\n",
    "    \n",
    "    y_train_accuracy = accuracy_score(y_train,y_train_preds)\n",
    "    y_test_accuracy = accuracy_score(y_test,y_test_preds)\n",
    "    \n",
    "    train_accuracy_list_epochs.append(y_train_accuracy)\n",
    "    test_accuracy_list_epochs.append(y_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Accuracy of the model against no.of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22cb9508da0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22cb94c3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,21),train_accuracy_list_epochs,'-',label = 'train')\n",
    "plt.plot(range(1,21),test_accuracy_list_epochs,'-',label = 'test')\n",
    "plt.xticks(range(1,21))\n",
    "plt.xlabel('No.of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer from the graph that after 3 epochs there is no much increase in accuracy. So we can set max_iter = 3. More epochs means more computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1003></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section803'></a>\n",
    "### 8.3 Evaluating performance of SGD Classifier for different learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SGDClassifier(), **alpha** is used **to calculate learning_rate**.\n",
    "So we will evaluate the model performace for different values of alpha =  [1e-4,3e-4,7e-4,1e-3,3e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_accuracy_list_alpha = []\n",
    "train_accuracy_list_alpha = []\n",
    "for i in [1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2]:\n",
    "    sgd = SGDClassifier(alpha = i,loss = 'log')\n",
    "    sgd_model = sgd.fit(X_train,y_train)\n",
    "    y_train_preds = sgd_model.predict(X_train)\n",
    "    y_test_preds = sgd_model.predict(X_test)\n",
    "    \n",
    "    y_train_accuracy = accuracy_score(y_train,y_train_preds)\n",
    "    train_accuracy_list_alpha.append(y_train_accuracy)\n",
    "    \n",
    "    y_test_accuracy = accuracy_score(y_test,y_test_preds)\n",
    "    test_accuracy_list_alpha.append(y_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Accuracy of the model against  alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEiCAYAAADTSFSPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22cb94e50f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2],train_accuracy_list_alpha,'-',label = 'train')\n",
    "plt.plot([1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2],test_accuracy_list_alpha,'-',label = 'test')\n",
    "plt.xticks([1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2], rotation='vertical')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Optimum alpha value seems to be 0.0007. From alpha = 0.001 test accuracy is dreacesing. That means model starts to overfit from aplha = 0.001.\n",
    " - Also after aplha = 0.001 there is a dip in both train and test accuracy. That means the ball is jumping here and there instead of converging to the minimum of cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1004></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section804\"></a>\n",
    "### 8.4 GridSearchCV on for SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV will help us to find right alpha and no.of iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sc1 = StandardScaler()\n",
    "X = sc1.fit_transform(features)\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"alpha\" : [1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2],\n",
    "    \"max_iter\" : list(range(1,21))\n",
    "}\n",
    "\n",
    "model = SGDClassifier(loss = 'log')\n",
    "clf = GridSearchCV(model, param_grid=params,scoring = 'accuracy',cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819327815299517\n",
      "Wall time: 10min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X, y)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'max_iter': 18}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819327815299517"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One shouldn't blindly take best parameters from GridSearchCV. The results should be cross checked with above graphs and final decision has to be taken based on accuracy and time taken to train the model to obtain that level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section9\"></a>\n",
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy** obtaing in **SGDClassifier model** is **almost same** as accuracy obtained in **LogisticRegression model** but in much less time.\n",
    "\n",
    "    - **SGDClassifier model** will be almost **10-15 times faster than LogisticRegression model** on this small train dataset of size 79,835. This will **make a huge difference when training on much larger datasets** in real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
